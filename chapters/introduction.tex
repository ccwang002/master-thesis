\chapter{Introduction}
\label{c:intro}

\section{Motivation}
\label{s:motivation}

%
% Why we need an online analysis platform
%

As more and more genome-wide studies rely on next-generation sequencing (NGS)
analysis, there is an increasing demand from both researchers and clinicians to
develop systems to orchestrate and interpret NGS data analysis pipelines. NGS
provides high read throughput which can generate total a few gigabases of read
sequences in a typical experiment run. However, before the read sequences yield
biologically meaningful results, they have to undergo many non-trivial steps
including genome alignment, sequence piling up, variant calling, and transcript
expression quantification which requires hours of computation by high-end
processors.

Combining the demand for fast computation speed and large data storage, NGS
analyses are mostly performed on powerful servers remotely using command line
interface. Therefore, the tools involved are often developed without graphical
interface due to maximum computation efficiency and lack of need. This kind of
terminal-based environment imposes a high barrier for especially biologists and
clinicians to enter. Furthermore, output of most analysis tools are shown as
log files or as file formats that are friendly for computers to parse but
cannot be easily interpreted by human without data cleaning and transformation.

As a NGS service core lab, many lab members have identified the burden of
routine NGS data processing and interpretation of results of commonly used
analysis pipelines. If a graphical summary report can be obtained after the
automated execution of analysis pipeline, many biologists and clinicians can
interpret the result themselves without extensive knowledge of how computers
work nor consulting bioinformatic researchers and thus improve the efficiency
of collaboration. On the other hand, for bioinformatic researchers, automated
execution of typical analysis pipelines can release them from routine tasks to
process incoming NGS experiment runs and focus more on innovative discovery and
interpretation of the NGS data itself.

Several analysis platforms have been proposed to help automate NGS analysis
pipeline with user friendly report or result viewer, including commercial
products such as DNAnexues \cite{:dnanexus} and Partek Flow \cite{:partek} and
open source projects such as Galaxy \cite{goecks2010:galaxy} and Genome
Modeling Tools \cite{griffith2015:genome}. However, these tools are either too
complex for biological researchers and clinicians to use, too simple for
researchers to build their own pipeline, or operating at a scale too large for
our lab to adapt. Therefore, the idea of building our own designed NGS online
analysis platform then emerged and became the main goal of my master thesis
study.


\section{Specific Aims}
\label{s:specific-aim}

%
% Propose the analysis platform and report generator
%

In this thesis study, an online platform, BioCloud, and a report generator,
BCReport, have been developed to help researchers automate their NGS analyses
and interpret the result based on the generated summary report. The online
platform builds on an account system to let individuals manage their sequencing
data sources and then design the experiment and sample settings to group their
data sources like their biological experiment set up. The designed experiment
can be used in different analysis pipelines that match the sequencing type of
the data sources, e.g., DNA or RNA sequencing. Each analysis pipeline combines
different tool chains and comes with their corresponding tool parameters for
user to adjust. After an analysis pipeline has been configured, it is submitted
to the job queue of online platform and will execute the underlying tool chains
when the computation resources are available.

As soon as the analysis execution has been completed, the report generator,
BCReport, is called and generates a summary report by parsing the results of
the execution. Report are given in HTML format so BCReport can be seamlessly
integrated into BioCloud and user can view their report via the BioCloud
website. In the report, the output of each tool is collected and parsed as
interactive charts and tables for user to explore the result. One of the
convenient features about the summary report is that results are grouped by
their samples and condition settings so user can compare the result between
different conditions naturally. They can also download the raw result output by
links provided in the report. Reports and results can be easily shared by
providing their URL link. Though the links are publicly accessible via
internet, they can be well protected if user apply different permission rules
for each analysis.



\section{Next-generation sequencing}
\label{s:ngs}

Next-generation sequencing (NGS) is a group of sequencing technologies that
succeeds automated Sanger sequencing which is considered as the first-generation
sequencing, by providing much higher read throughput while shorter read length
that reduces the cost and time to complete genome-wide sequencing study
\cite{metzker2010:sequencing}. Generally speaking, a NGS experiment undergoes
steps of template preparation, sequencing, imaging and data analysis. During
template preparation, DNA samples are broken into fragments of shorter length,
which the desired length varies across different NGS technologies but generally
in the range of few tens to few thousands of nucleotides. Proper adapters and
barcode will be added to these DNA fragments for further manipulation, fixation
on the sequencing chip, and mixed multiple samples in one experiment run. Each
template will then be positioned separately on the sequencing chip by for
example, ligation with adapter in illumina NGS technology. Sequencing is done
by multiple cycles which read out one base at a time using deoxyribonucleotide
triphosphates (dNTPs) with four or two fluorescent chemical labels and
reversible terminator. Reading base detection in a sequencing cycle is done by
image capturing the fluorescent emission of all templates on chip. Sequencing
and imaging steps enables NGS determine the sequencing millions of DNA
fragments in parallel.

Next-generation sequencing has been playing an important role in current
genomic researches. In the last decade, next-generation sequencing has become
the \textit{de facto} way to understand genome \cite{vandijk2014:ten} including
quantification of transcriptome expression \cite{wang2009:rnaseq}, variant
calling and genotype inference \cite{nielsen2011:genotype}. The ability to
determine novel sequence reads opens the door for \textit{de novo}
transcriptome and genome assembly. Comparing to the renowned Human Genome
Project \cite{lander2001:initial}, finishing a new organism assembly now
requires significantly shorter time and lower budget and makes study of
non-model organisms becoming feasible. As the sequencing cost for a whole human
genome passing below USD 1,000, we can expect a wider application of NGS and
more and more fields adopt this technology.

% single-cell sequencing
New single-cell sequencing technology, often viewed as the third generation
sequencing, has enabled the genomic research down to the cellular level in the
past few years \cite{gawad2016:singlecell}. New insights may be found by
applying single-cell sequencing to heterogeneous samples, for example, studying
somatic mutations in tumor samples and analyzing individual genomes in
metagenomics. Although the sequencing data from single-cell sequencing may have
different properties with that from NGS, including statistical distribution and
sequencing error model, the overall workflow and file format for data storage
shares a lot in common. Therefore the currently developed analysis platform can
still analyze data from future sequencing technologies without large
modification.



\section{Genome reference}
\label{s:genome-ref}

Once a NGS experiment is complete, the sequence reads are merely sequences of
DNA fragments and lack biological meaning. However, since fragments are often
overlap with each other, one can concatenate fragments into longer sequences
called scaffolds. Multiple scaffolds can later construct chromosomes and hence
complete a whole genome sequencing. The whole process of joining reads into
scaffolds and chromosomes is referred to as genome assembly. The counterpart
for RNA sequencing and cDNA fragments is referred to as transcriptome assembly.
If such sequence assembly is done on a novel organism, the assembly is called
a \textit{de novo} assembly.

However, \textit{de novo} assembly requires high sequencing coverage and takes
substantial computing resources, which is not feasible for normal applications.
Also, it is hard to comparing the results based on genome from different
studies if people rely on their own distinct genome assembly. Many genomic
studies requires integration of multiple annotations including gene, transcript,
and variant formation, thus having sufficient number of sequencing runs, a
consensus of genome assembly forms the genome reference. A genome reference
needs not to be the exact sequence of a specimen but represents the most common
sequence of the given genomic region.

Once a genome reference is released, different types of annotations, e.g.,
different gene databases, are aligned to the new genome reference. These
annotations can be browsed by the given chromosomal location via genome
browser. Normal applications now only needs to align to the genome reference,
which not only save both time and cost, but also are able to access to many
other annotations. Thus for model organisms like human and mouse, analyses
generally relies on certain version of genome reference.

% time and cost
% hard to compare other result
% annotations

NGS currently still has its limitations to cover full genome in a sequence run.
There are still regions and special sequencing patterns which are hard to
sequence, including reads with short repeat and high GC\% content; regions in
centromeres and telomeres. Even if they can be sequenced correctly, their
repetitive sequences make it hard to figure out the right assembly. Therefore,
even for the mature genome projects like human genome project, the genome
sequence is continually updated. The latest human genome reference GRCh38.p7
was released in March 2016, and it still contains 805 scaffolds with 349 gaps
\cite{:grch38p7}, whereas the first version released in 2001 contains around
150,000 gaps \cite{2010:e-pluribus-unum}.

% allelic diversity -- alternative loci
% patch

It should be noted that there are two types of genome reference updates: major
and minor updates. Major updates, e.g., from hg19 to GRCh38, breaks the
chromosomal location compatibility, whose genomic coordinates of primary
assemblies, e.g., major chromosomes and plasmids, will change. One could use
tools such as liftOver to handle the coordination conversion. On the contrary,
minor updates, e.g., from GRCh38 to GRCh38.p1, don't introduce backward
breakage on primary assemblies, but release the updates as patches and
alternative loci. Patches fix the sequencing errors or fill in the gap between
scaffolds of primary assembly, which will be displayed along their
corresponding genomic regions and overwrites the primary assembly in the next
major release. Alternative loci appear in when some regions have high allelic
diversity so one common sequence cannot well represent the specified gnomic
region. For example, major histocompatibility complex (MHC) region on
chromosome 6 has 7 alternative representations.


%
% Explain about the general NGS analysis workflow
%

\section{General NGS analysis workflow}

Except for \textit{de novo} assembly, general NGS analysis involves the
following analysis steps: sequencing quality check, genome alignment,
annotation, and statistical inference. During sequencing, the sequencer records
each read base with a Phred quality score $q$, where the probability of the
base being erroneously sequenced $P_q$ is $P_q = 10^{\frac{-q}{10}}$. A read
base with quality lower than 30 implies the probability of sequencing error at
this base is higher than 0.1\%. How quality is measured depends on the
sequencing technology. For example, the quality score is computed based on the
fluorescent intensity on Illumina platforms. Quality of all sequence reads will
be first checked to determine if the experiment run performed as expected.
Reads with low quality can be filtered or partially trimmed during this stage.

% genome alignment
Then sequence reads are aligned to the genome using certain version of genome
reference. Though the generated sequence reads are shorter, they are long
enough to determine their genomic location. Aligned reads may have mismatched
sequences with genome reference and the all alignment information will be
stored in the alignment result file, usually in the format of BAM or SAM files.
Alignment methods of RNA and DNA sequencing are different, since RNA-Seq the
sequences are the product of splicing event and will map to multiple distinct
exon regions during alignment. After sequences have been aligned to the genome,
user can annotate the reads about the gene information it locates, whether the
variant is a common SNP. The annotation in use will depend on the type of
sequencing and intended application, as long as annotation and the sample
alignment share the same version of genome reference. With proper annotation,
statistical inference and modeling help researcher answer questions like how a
gene or transcript is expressed, whether a genomic location has mutation, or a
genomic region has copy number gain or loss.


% \section{RNA and DNA sequencing application}
% RNA-Seq
% - differential expression
% - novel isoform/transcript discovery
% - de novo transcriptome assembly
%
% DNA-Seq
% - SNV variant calling
% - germline mutation
% - somatic mutation
% - CNV
% - de novo assembly


% vim: set textwidth=79 spell:
