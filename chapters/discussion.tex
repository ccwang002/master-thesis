\chapter{Discussions}
\label{c:discussion}


\section{Data source uploading}

BioCloud does not offer the ability to upload data sources from local to
BioCloud's data storage since the uploading is extremely hard to implement
correctly and few people store their data in local anyway. Given uploading
speed 1MB/s for normal ADSL connection and 10MB/s for education environment,
uploading a pair-end sample of 22M 63 base pair long reads (12GiB disk space)
takes about 3.5 hours for normal ADSL connection or 20 minutes for education
network to complete.

Upload a dataset having 10 samples may take days for users of low connection
speed. Though a lot of HTTP-based uploading frameworks exist, they are only
suitable for uploading few hundreds of MBs at a time. Moreover, most users may
not upload any data sources in their lifetime since their raw sequencing data
exist on the server in the very first place. BioCloud supports reading
soft-linked data sources so putting data under BioCloud does not necessarily
move the data nor increase the total disk usage. When data source transferring
is needed, one can resort to traditional while robust tools  such as
\texttt{rsync}, \texttt{sftp} and \texttt{ftp} to help transfer large files.


\section{Supported analyses}

%- Why use STAR instead of Tophat
%    - faster
%    - citation about the accuracy
% - Specify the test and normalization done for other DE RNA-SEq pipeline
%    - t-test
%    - Normalization via FPKM

In Chapter~\ref{c:result} we showed a RNA-Seq analysis using STAR as genome
aligner and Cufflinks to infer the gene expression. Currently BioCloud also
supports Tophat2 as the aligner. It was not used in the demonstration mainly
due to the computation time of Tophat2 is about 100 times that of STAR. Study
by \citeauthor{engstrom2013:systematic} supported the usage of STAR over
Tophat2 for better accuracy and specificity \cite{engstrom2013:systematic}.
Normalization in this pipeline was done within Cufflinks stage using FPKM unit.
For differential expression statistical test, $t$-test was used by Cuffdiff
\cite{rapaport2013:comprehensive}. For other RNA-Seq differential expression
pipelines, different tools and methods may be adopted for normalization and
statistical tests. For DNA-Seq variant calling, the pipeline of BWA MEM as
aligner and VarScan as variant caller is supported.

% - Specify what BioCloud can or cannot do:
%     - Genome organism: Human and possibly mouse
%     - Analysis pipeline:
%         - RNA-Seq differential expression
%         - DNA-Seq variant calling
%         - DID NOT TEST miRNA and lncRNA expression
%         - DID NOT TEST GO enrichment analysis
%         - CANNOT de novo
%         - CANNOT ChIP seq

BioCloud is only tested with human sequencing samples and genome, though it is
possible to support other well modelled organisms such as mouse and rat.
Similarly, RNA-Seq pipeline is possible to quantify the expression of miRNA or
lncRNA with proper annotation sources, while the pipeline has not been tested.
BioCloud currently can not perform GO enrichment analysis, \textit{de novo}
assembly, and ChIP-Seq analysis. One needs to provide the corresponding
annotations, pipeline execution script, and report template design to customize
a new analysis pipeline.



\section{Pipeline extension}
\label{s:pipeline-extension}

Currently BioCloud defines DNA-Seq and RNA-Seq analysis pipelines that call
germline variants shared in the same condition and infer differential
expression across multiple conditions. However, NGS applications are much more
diverse thus the ability to extend current pipelines or write new custom
pipelines is important. BioCloud was built with extensibility in mind thus it
is possible to add new pipelines by user. BioCloud heavily relies on the class
inheritance to re-use code blocks. A new pipeline requires user to define a new
analysis design, its underlying pipeline execution commands, and the code and
report template to generate summary report.

We start by defining the analysis design of a new analysis pipeline. An
analysis design requires three major components: database model to store
analysis parameters, design form that interacts with user's input, and the
definition of execution stages. BioCloud defines an abstract analysis pipeline
which takes only an experiment design and genome reference to execute. It has
no execution stage and executes zero command to complete a analysis. In this
manner, large proportion of code are re-used. However, defining the interactive
design form, e.g., option sets for tools of same stage, still requires many
customizations, since it requires combining code logics from backend database
fields with logics from the reactive frontend. An architecture for specifying
option sets may be proposed to hide the implementation detail. But the
architecture can still be useless if user want nested option sets or
interaction with given experiment design. On the other hand, if an analysis
design does not contain any option sets, it will be straight forward to build
by inheriting the abstract analysis.

For defining the underlying pipeline execution commands, since different
pipelines share few similarities in how they are executed, user have to control
the execution flow oneself. Basically, an execution of analysis that passes to
the job queue is one lengthy Python function call, and user can define any
command they want in the function call. Tools already defined in builtin
pipelines like FastQC can be re-used as subroutines. However, writing an
analysis execution flow can be extremely trivial and error prone. Most tools
are executed via command line and thus the developer will repeat the same
pattern for each tool in use. Also, since the analysis is executed in one big
pack of job, computing resources will be wasted if the underlying tool cannot
utilize multiple threads but still block the entire queue. It also repeats the
execution if a tool with same input and argument appears in multiple pipelines.
The issue about customization of pipeline execution will be addressed in the
following section.

For report generation, the situation is similar to that of defining underlying
pipeline execution. An abstract summary report is defined by BioCloud which
handles the processing of analysis information and defines the workflow. User
summarize the result of a new tool by creating a new report stage. In the stage
user define how the results are parsed and the HTML template and static
Javascript and CSS files for report rendering. Even though an abstract summary
report is defined and user can utilize the existed result parsers, it still
requires substantial effort to customize a new interactive figure in summary
report. Due to the different output formats for different tools, even tools of
similar function may not generate the same figures and tables in the summary
report. For example, both BWA and STAR are genome aligner, the ways they
describe the alignment types of the input sequence reads are different, though
one can still conclude the proportion of unique and multiple alignment from
their results.



\section{Integration with other frameworks}

Some of the tools mentioned in
Section~\ref{s:pipeline-execution-tool}~and~\ref{analysis-report-generation}
can help improve the functionalities of BioCloud. Snakemake
\cite{koster2012:snakemakea} defines a pipeline execution by set of rules. In
each rule, it specifies the inputs and outputs pattern, combining with a set of
command line command or Python functions which ideally provide the output files
given the input files. By writing execution rules instead of the precise way of
how the analysis should be executed, job queue can finer control the computing
resources and parallelize the execution of independent subroutines. Updating
the stage status will be harder to determine since now commands of a stage need
not to execute together. Some sentinel commands can be designated for stage
status update by specifying the input to be all outputs of the current stage.
Snakemake supports sending an analysis job to qsub computing cluster, which
splits the analysis into independent tasks to fully utilize all the available
nodes of the cluster. Similarly, one could also integrates bcbio-nextgen
\cite{:bcbionextgen,guimera2012:bcbionextgen} and combines its abundant
resources of analysis workflows with BioCloud's analysis design form. It also
supports submitting jobs and storing results on virtual private server (VPS)
provides such as Amazon and Google.

% vim: set textwidth=79 spell:
